{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self, shape=(60,2,13,3)):\n",
    "        self.shape = shape\n",
    "        \n",
    "        \n",
    "    def reset(self, new_example, true_acc, is_clapping): # new_example = frames*(v,d), v = vertices of 13 parts, d = vel of 13 parts\n",
    "        self.info = new_example # store v and d in one tensor (60frames*13joints*2features*3axis)\n",
    "        self.pos = new_example[0][0] # the first state of new example # np.random.rand(1,3)\n",
    "        self.vel = new_example[0][1] # the first state of new example # np.random.rand(1,3)\n",
    "        self.frame = 0\n",
    "        self.is_clapping = is_clapping\n",
    "        self.true_acc = true_acc # store true acc in one tensor (60frames*13joints*1feature*3axis)\n",
    "        self.max_frame = self.shape[0]-1\n",
    "        \n",
    "    def state(self):\n",
    "        # flatten the vd matrix size=(2*13*3) into 1 dimension size=(1*78)\n",
    "        # flatten the a matrix size=(1*13*3) into 1 dimension size=(1*39)\n",
    "        return self.info[self.frame].reshape((1,-1)).copy(), self.true_acc[self.frame].reshape((1,-1)).copy()\n",
    "    \n",
    "    def update(self):\n",
    "        self.frame += 1 # move to next frame\n",
    "        if self.frame == self.max_frame: # give reward if it is last frame\n",
    "            if is_clapping:\n",
    "                return 1\n",
    "            else\n",
    "                return -1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((10,10))\n",
    "a.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#if using Theano with GPU\n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env, explore=0.1, discount=0.95, hidden_size=10, memory_limit=5000):\n",
    "        self.env = env\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden_size, input_shape=(2*13*3,), activation='relu'))\n",
    "        model.add(Dense(hidden_size, activation='relu'))\n",
    "        model.add(Dense(13*3))\n",
    "        model.compile(loss='mse', optimizer='sgd')\n",
    "        self.Q = model\n",
    "        \n",
    "        # experience replay:\n",
    "        # remember states to \"reflect\" on later\n",
    "        self.memory = deque([], maxlen=memory_limit)\n",
    "        \n",
    "        self.explore = explore # give some chance to randomly assign acc to explore new possiblities\n",
    "        self.discount = discount # gamma of weight\n",
    "    \n",
    "    def predict_acc(self):\n",
    "        if np.random.rand() <= self.explore:\n",
    "            return np.random.rand(1, 13)\n",
    "        state = self.env.state\n",
    "        q = self.Q.predict(state)\n",
    "        \n",
    "        return q[0]\n",
    "    \n",
    "    def remember(self, state, acc, true_acc, reward):\n",
    "        # the deque object will automatically keep a fixed length\n",
    "        self.memory.append((state, acc, true_acc, reward))\n",
    "    \n",
    "    \n",
    "    # between every action, it will pick batch_size previous states/actions that the agent \"remembers\" to train\n",
    "    def _prep_batch(self, batch_size):\n",
    "        if batch_size > self.memory.maxlen:\n",
    "            Warning('batch size should not be larger than max memory size. Setting batch size to memory size')\n",
    "            batch_size = self.memory.maxlen\n",
    "            \n",
    "        batch_size = min(batch_size, len(self.memory))\n",
    "        \n",
    "        inputs = []\n",
    "        targets = []\n",
    "        \n",
    "        # prep the batch\n",
    "        # inputs are states, outputs are values over actions\n",
    "        batch = random.sample(list(self.memory), batch_size) # randomly get some states in the memory\n",
    "        random.shuffle(batch)\n",
    "        \n",
    "        for state, acc, true_acc, reward in batch:\n",
    "            inputs.append(state)\n",
    "            target = true_acc\n",
    "            \n",
    "            # debug, \"this should never happen\"\n",
    "            assert not np.array_equal(state, next_state)\n",
    "            \n",
    "            # non-zero reward indicates terminal state\n",
    "#             if reward:\n",
    "#                 target[action] = reward\n",
    "#             else:\n",
    "#                 # reward + gamma * max_a' Q(s',a')\n",
    "#                 Q_sa = np.max(self.Q.predict(next_state)[0])\n",
    "#                 target[action] = reward + self.discount * Q_sa\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            targets.append(target)\n",
    "            \n",
    "        # to numpy matrices\n",
    "        return np.vstack(inputs), np.vstack(targets)\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        inputs, targets = self._prep_batch(batch_size)\n",
    "        loss = 0\n",
    "        for i in range(len(inputs)):\n",
    "            loss += pow(self.discount,self.env.max_frame - self.env.frame)*self.Q.train_on_batch(inputs[i], targets[i])\n",
    "        return loss\n",
    "    \n",
    "    def save(self, fname):\n",
    "        self.Q.save_weights(fname)\n",
    "    \n",
    "    def load(self, fname):\n",
    "        self.Q.load_weights(fname)\n",
    "        print(self.Q.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import sleep\n",
    "game = Game()\n",
    "agent = Agent(game)\n",
    "\n",
    "print('training...')\n",
    "epochs = 100 # number of training videos\n",
    "batch_size = 60 # number of \"experiences\" we want to train from the previous decisions\n",
    "fname = 'clapping_weights.h5'\n",
    "\n",
    "# keep track of past record_len results\n",
    "record_len = 100\n",
    "record = deque([], record_len)\n",
    "\n",
    "for i in range(epochs):\n",
    "    new_example = # load new training video data\n",
    "    is_clapping = # is the video clapping?\n",
    "    game.reset(new_example, is_clapping)\n",
    "    reward = 0\n",
    "    loss = 0\n",
    "    \n",
    "    # rewards only given at end of game\n",
    "    while reward == 0:\n",
    "        prev_state, true_acc = game.state\n",
    "        acc = agent.predict_acc()\n",
    "        reward = game.update()\n",
    "        \n",
    "        # debug, \"this should never happen\"\n",
    "        assert not np.array_equal(new_state, prev_state)\n",
    "        \n",
    "        agent.remember(prev_state, acc, true_acc, reward)\n",
    "        loss += agent.replay(batch_size)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print('epoch: {:04d}/{} | loss: {:.3f} | win rate: {:.3f}\\r'.format(i+1, epochs, loss, sum(record)/len(record) if record else 0))\n",
    "    \n",
    "    record.append(reward if reward == 1 else 0)\n",
    "\n",
    "agent.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2,4,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 14, 15])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[[1,2,3],\n",
    "               [4,5,6],\n",
    "               [7,8,9],\n",
    "               [10,11,12]],\n",
    "              \n",
    "              [[13,14,15],\n",
    "               [16,17,18],\n",
    "               [19,20,21],\n",
    "               [22,23,24]]\n",
    "             ])\n",
    "b[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "c.append((1,0))\n",
    "c.append((2,0))\n",
    "c.append((3,0))\n",
    "c.append((4,0))\n",
    "c.append((5,0))\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (3, 0), (2, 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(c, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "        model = Sequential()\n",
    "        model.add(Dense(100, input_shape=(13*2*3,), activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(5))\n",
    "        model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x123f88278>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 78)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = np.zeros((13,2,3))\n",
    "# rs.shape\n",
    "rs = rs.reshape((1,-1)).copy()\n",
    "rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "inputs.append(rs)\n",
    "inputs.append(rs)\n",
    "inputs.append(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "p = 5\n",
    "if p:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30745461, 0.66801875, 0.43939106]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=(60,2,13,3)\n",
    "shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.zeros((5,1))\n",
    "# rs.shape\n",
    "out = out.reshape((1,-1)).copy()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outputs.append(out)\n",
    "outputs.append(out)\n",
    "outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 78)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
